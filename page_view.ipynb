{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2hBIAQRlCZB"
      },
      "source": [
        "# Page Views\n",
        "\n",
        "Data about page views on Wikipedia is available at https://dumps.wikimedia.org and there is documentation about the [definition of a page view](https://meta.wikimedia.org/wiki/Research:Page_view) and the [format of lines](https://dumps.wikimedia.org/other/pagecounts-ez/) in the file. In the class project, you will need to use page view data that we'll provide for ALL of English Wikipedia from the month of August 2021, which is more than 10.7 million viewed articles. The code below shows how we generate that data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAdNnF04t3Hd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import bz2\n",
        "from functools import partial\n",
        "from collections import Counter\n",
        "import pickle\n",
        "from itertools import islice\n",
        "from xml.etree import ElementTree\n",
        "import codecs\n",
        "import csv\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Hv947ULyiT5"
      },
      "outputs": [],
      "source": [
        "# Using user page views (as opposed to spiders and automated traffic) for the month of August 2021\n",
        "pv_path = 'https://dumps.wikimedia.org/other/pageview_complete/monthly/2021/2021-08/pageviews-202108-user.bz2'\n",
        "p = Path(pv_path) \n",
        "pv_name = p.name\n",
        "pv_temp = f'{p.stem}-4dedup.txt'\n",
        "pv_clean = f'{p.stem}.pkl'\n",
        "# Download the file (2.3GB) \n",
        "!wget -N $pv_path\n",
        "# Filter for English pages, and keep just two fields: article ID (3) and monthly \n",
        "# total number of page views (5). Then, remove lines with article id or page \n",
        "# view values that are not a sequence of digits.\n",
        "!bzcat $pv_name | grep \"^en\\.wikipedia\" | cut -d' ' -f3,5 | grep -P \"^\\d+\\s\\d+$\" > $pv_temp\n",
        "# Create a Counter (dictionary) that sums up the pages views for the same \n",
        "# article, resulting in a mapping from article id to total page views.\n",
        "wid2pv = Counter()\n",
        "with open(pv_temp, 'rt') as f:\n",
        "  for line in f:\n",
        "    parts = line.split(' ')\n",
        "    wid2pv.update({int(parts[0]): int(parts[1])})\n",
        "# write out the counter as binary file (pickle it)\n",
        "with open(pv_clean, 'wb') as f:\n",
        "  pickle.dump(wid2pv, f)\n",
        "# read in the counter\n",
        "# with open(pv_clean, 'rb') as f:\n",
        "# #   wid2pv = pickle.loads(f.read())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "page_view.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": false,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}