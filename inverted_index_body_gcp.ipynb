{"cells":[{"cell_type":"markdown","metadata":{"id":"hWgiQS0zkWJ5"},"source":["***Important*** DO NOT CLEAR THE OUTPUT OF THIS NOTEBOOK AFTER EXECUTION!!!"],"id":"hWgiQS0zkWJ5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0ccf76b","nbgrader":{"grade":false,"grade_id":"cell-Worker_Count","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"cf88b954-f39a-412a-d87e-660833e735b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["NAME          PLATFORM  WORKER_COUNT  PREEMPTIBLE_WORKER_COUNT  STATUS   ZONE           SCHEDULED_DELETE\r\n","cluster-104f  GCE       2                                       RUNNING  us-central1-c\r\n"]}],"source":["# if the following command generates an error, you probably didn't enable \n","# the cluster security option \"Allow API access to all Google Cloud services\"\n","# under Manage Security â†’ Project Access when setting up the cluster\n","!gcloud dataproc clusters list --region us-central1"],"id":"c0ccf76b"},{"cell_type":"markdown","metadata":{"id":"01ec9fd3"},"source":["# Imports & Setup"],"id":"01ec9fd3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"32b3ec57","nbgrader":{"grade":false,"grade_id":"cell-Setup","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"fc0e315d-21e9-411d-d69c-5b97e4e5d629"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}],"source":["!pip install -q google-cloud-storage==1.43.0\n","!pip install -q graphframes"],"id":"32b3ec57"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5609143b","nbgrader":{"grade":false,"grade_id":"cell-Imports","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"a24aa24b-aa75-4823-83ca-1d7deef0f0de"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m<ipython-input-5-f2ff9dc83876>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"]}],"source":["import pyspark\n","import sys\n","from collections import Counter, OrderedDict, defaultdict\n","import itertools\n","from itertools import islice, count, groupby\n","import pandas as pd\n","import math\n","import os\n","import re\n","from operator import itemgetter\n","import nltk\n","from nltk.stem.porter import *\n","from nltk.corpus import stopwords\n","from time import time\n","from pathlib import Path\n","import pickle\n","import pandas as pd\n","from google.cloud import storage\n","\n","import hashlib\n","def _hash(s):\n","    return hashlib.blake2b(bytes(s, encoding='utf8'), digest_size=5).hexdigest()\n","\n","nltk.download('stopwords')"],"id":"5609143b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"b10cc999","nbgrader":{"grade":false,"grade_id":"cell-jar","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"8f93a7ec-71e0-49c1-fc81-9af385849a90"},"outputs":[{"name":"stdout","output_type":"stream","text":["-rw-r--r-- 1 root root 247882 Nov 25 06:29 /usr/lib/spark/jars/graphframes-0.8.2-spark3.1-s_2.12.jar\r\n"]}],"source":["# if nothing prints here you forgot to include the initialization script when starting the cluster\n","!ls -l /usr/lib/spark/jars/graph*"],"id":"b10cc999"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3f86f11","nbgrader":{"grade":false,"grade_id":"cell-pyspark-import","locked":true,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["from pyspark.sql import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext, SparkConf, SparkFiles\n","from pyspark.sql import SQLContext\n","from graphframes import *"],"id":"d3f86f11"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5be6dc2a","nbgrader":{"grade":false,"grade_id":"cell-spark-version","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"07b4e22b-a252-42fb-fe46-d9050e4e7ca8","scrolled":true},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cluster-104f-m.us-central1-c.c.sise-ir-21-22.internal:37229\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f8b0c1fc400>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["spark"],"id":"5be6dc2a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"7adc1bf5","nbgrader":{"grade":false,"grade_id":"cell-bucket_name","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# Put your bucket name below and make sure you can access it without an error\n","bucket_name = 'search_engine_bucket' \n","client = storage.Client()\n","blobs = client.list_blobs(bucket_name)\n","for b in blobs:\n","    print(b.name)"],"id":"7adc1bf5"},{"cell_type":"markdown","metadata":{"id":"13ZX4ervQkku"},"source":["***GCP setup is complete!*** If you got here without any errors you've earned 10 out of the 35 points of this part."],"id":"13ZX4ervQkku"},{"cell_type":"markdown","metadata":{"id":"c0b0f215"},"source":["# Building an inverted index"],"id":"c0b0f215"},{"cell_type":"markdown","metadata":{"id":"02f81c72"},"source":["Here, we read the entire corpus to an rdd, directly from Google Storage Bucket and use your code from Colab to construct an inverted index."],"id":"02f81c72"},{"cell_type":"code","execution_count":null,"metadata":{"id":"b1af29c9","scrolled":false},"outputs":[],"source":["full_path = \"gs://wikidata_preprocessed/*\"\n","parquetFile = spark.read.parquet(full_path)\n","doc_text_pairs = parquetFile.select(\"text\", \"id\").rdd\n","doc_title_pairs = parquetFile.select(\"id\", \"title\").rdd"],"id":"b1af29c9"},{"cell_type":"markdown","metadata":{"id":"f6375562"},"source":["We will count the number of pages to make sure we are looking at the entire corpus. The number of pages should be more than 6M"],"id":"f6375562"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d89a7a9a"},"outputs":[],"source":["# Count number of wiki pages\n","parquetFile.count()"],"id":"d89a7a9a"},{"cell_type":"markdown","metadata":{"id":"gaaIoFViXyTg"},"source":["Let's import the inverted index module. Note that you need to use the staff-provided version called `inverted_index_gcp.py`, which contains helper functions to writing and reading the posting files similar to the Colab version, but with writing done to a Google Cloud Storage bucket."],"id":"gaaIoFViXyTg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"04371c88","outputId":"327fe81b-80f4-4b3a-8894-e74720d92e35"},"outputs":[{"name":"stdout","output_type":"stream","text":["inverted_index_gcp.py\r\n"]}],"source":["# if nothing prints here you forgot to upload the file inverted_index_gcp.py to the home dir\n","%cd -q /home/dataproc\n","!ls inverted_index_body_gcp.py"],"id":"04371c88"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2d3285d8","scrolled":true},"outputs":[],"source":["# adding our python module to the cluster\n","sc.addFile(\"/home/dataproc/inverted_index_body_gcp.py\")\n","sys.path.insert(0,SparkFiles.getRootDirectory())"],"id":"2d3285d8"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2477a5b9"},"outputs":[],"source":["from inverted_index_body_gcp import InvertedIndex"],"id":"2477a5b9"},{"cell_type":"markdown","metadata":{"id":"72bcf46a"},"source":["**YOUR TASK (10 POINTS)**: Use your implementation of `word_count`, `reduce_word_counts`, `calculate_df`, and `partition_postings_and_write` functions from Colab to build an inverted index for all of English Wikipedia in under 2 hours.\n","\n","A few notes: \n","1. The number of corpus stopwords below is a bit bigger than the colab version since we are working on the whole corpus and not just on one file.\n","2. You need to slightly modify your implementation of  `partition_postings_and_write` because the signature of `InvertedIndex.write_a_posting_list` has changed and now includes an additional argument called `bucket_name` for the target bucket. See the module for more details.\n","3. You are not allowed to change any of the code not coming from Colab. "],"id":"72bcf46a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4b6ee29","nbgrader":{"grade":false,"grade_id":"cell-token2bucket","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["english_stopwords = frozenset(stopwords.words('english'))\n","corpus_stopwords = [\"category\", \"references\", \"also\", \"external\", \"links\", \n","                    \"may\", \"first\", \"see\", \"history\", \"people\", \"one\", \"two\", \n","                    \"part\", \"thumb\", \"including\", \"second\", \"following\", \n","                    \"many\", \"however\", \"would\", \"became\"]\n","\n","all_stopwords = english_stopwords.union(corpus_stopwords)\n","RE_WORD = re.compile(r\"\"\"[\\#\\@\\w](['\\-]?\\w){2,24}\"\"\", re.UNICODE)\n","\n","NUM_BUCKETS = 124\n","def token2bucket_id(token):\n","  return int(_hash(token),16) % NUM_BUCKETS\n","\n","# PLACE YOUR CODE HERE\n","\n","##################################################################################################\n","\n","def word_count(text, id):\n","  tokens = [token.group() for token in RE_WORD.finditer(text.lower())]\n","  filtered_tokens = [tok for tok in tokens if tok not in all_stopwords]\n","  count = Counter(filtered_tokens)\n","  return [(k,(id,v)) for k,v in count.items()]\n","\n","##################################################################################################\n","\n","def reduce_word_counts(unsorted_pl):\n","  return sorted(unsorted_pl)\n","\n","##################################################################################################\n","\n","def calculate_df(postings):\n","  return postings.mapValues(lambda x: len(x))\n","\n","##################################################################################################\n","\n","def partition_postings_and_write(postings):\n","  posting_with_bucket = postings.map(lambda x: (token2bucket_id(x[0]), (x[0],x[1])))\n","  b_w_pl = posting_with_bucket.groupByKey().map(lambda x : (x[0], list(x[1])))\n","  posting_locs_dict_rdd = b_w_pl.map(lambda x: InvertedIndex.write_a_posting_list(x, bucket_name))\n","  return posting_locs_dict_rdd\n","\n","##################################################################################################\n","\n","def doc_len_mapping_creator(text, id):\n","  tokens = [token.group() for token in RE_WORD.finditer(text.lower())]\n","  filtered_tokens = [tok for tok in tokens if tok not in all_stopwords]\n","  return [(id, len(filtered_tokens))]\n","\n","##################################################################################################\n","\n","def doc_title_mapping_creator(id, title):\n","    return [(id,title)]\n","\n","##################################################################################################\n","\n","def calculate_idf(postings):\n","  N = doc_text_pairs.count()\n","  pairs = postings.map(lambda tup: (tup[0],len(tup[1])))\n","  idf_calc = pairs.map(lambda tup :(tup[0], math.log((N/tup[1]),10)))\n","  return idf_calc"],"id":"a4b6ee29"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0b5d7296","nbgrader":{"grade":false,"grade_id":"cell-index_construction","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# time the index creation time\n","t_start = time()\n","\n","# word counts map\n","word_counts_body = doc_text_pairs.flatMap(lambda x: word_count(x[0], x[1]))\n","postings_body = word_counts_body.groupByKey().mapValues(reduce_word_counts)\n","\n","# filtering postings and calculate df\n","postings_body_filtered = postings_body.filter(lambda x: len(x[1]) > 50)\n","df_dictionary = calculate_df(postings_body_filtered).collectAsMap()\n","\n","# dictionary mapping doc id - doc len\n","doc_len_dictionary = doc_text_pairs.flatMap(lambda x: doc_len_mapping_creator(x[0], x[1])).collectAsMap()\n","\n","# dictionary mapping doc id - doc title\n","doc_title_dictionary = doc_title_pairs.flatMap(lambda x: doc_title_mapping_creator(x.id, x.title)).collectAsMap()\n","\n","# idf dictionary\n","idf_dictionary = calculate_idf(postings_body_filtered).collectAsMap()\n","\n","# partition posting lists and write out\n","_ = partition_postings_and_write(postings_body_filtered).collect()\n","\n","index_const_time = time() - t_start"],"id":"0b5d7296"},{"cell_type":"code","execution_count":null,"metadata":{"id":"348pECY8cH-T","nbgrader":{"grade":true,"grade_id":"cell-index_const_time","locked":true,"points":10,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["# test index construction time\n","index_const_time"],"id":"348pECY8cH-T"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Opl6eRNLM5Xv","nbgrader":{"grade":true,"grade_id":"collect-posting","locked":true,"points":0,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["# collect all posting lists locations into one super-set\n","super_posting_locs = defaultdict(list)\n","for blob in client.list_blobs(bucket_name, prefix='body_index'):\n","  if not blob.name.endswith(\"pickle\"):\n","    continue\n","  with blob.open(\"rb\") as f:\n","    posting_locs = pickle.load(f)\n","    for k, v in posting_locs.items():\n","      super_posting_locs[k].extend(v)"],"id":"Opl6eRNLM5Xv"},{"cell_type":"markdown","metadata":{"id":"VhAV0A6dNZWY"},"source":["Putting it all together"],"id":"VhAV0A6dNZWY"},{"cell_type":"code","execution_count":null,"metadata":{"id":"54vqT_0WNc3w"},"outputs":[],"source":["# Create inverted index instance\n","inverted = InvertedIndex()\n","\n","# Adding the posting locations dictionary to the inverted index\n","inverted.posting_locs = super_posting_locs\n","\n","# Add the token - df dictionary to the inverted index\n","inverted.df = df_dictionary\n","\n","# Add the idf dictionary to the inverted index\n","inverted.idf = idf_dictionary\n","\n","# Add the doc_id - title dictionary to the inverted index\n","inverted.doc_title_mapping = doc_title_dictionary\n","\n","# Add the doc_id - length dictionary to the inverted index\n","inverted.doc_len_mapping = doc_len_dictionary\n","\n","# write the global stats out\n","inverted.write_index('.', 'body_index')\n","\n","# upload to gs\n","index_src = \"body_index.pkl\"\n","index_dst = f'gs://{bucket_name}/body_index/{index_src}'\n","!gsutil cp $index_src $index_dst"],"id":"54vqT_0WNc3w"},{"cell_type":"code","execution_count":null,"metadata":{"id":"msogGbJ3c8JF","nbgrader":{"grade":false,"grade_id":"cell-index_dst_size","locked":true,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["!gsutil ls -lh $index_dst"],"id":"msogGbJ3c8JF"},{"cell_type":"markdown","metadata":{"id":"fc0667a9","nbgrader":{"grade":false,"grade_id":"cell-2a6d655c112e79c5","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["# PageRank"],"id":"fc0667a9"},{"cell_type":"markdown","metadata":{"id":"fdd1bdca","nbgrader":{"grade":false,"grade_id":"cell-2fee4bc8d83c1e2a","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["**YOUR TASK (10 POINTS):** Compute PageRank for the entire English Wikipedia. Use your implementation for `generate_graph` function from Colab below."],"id":"fdd1bdca"},{"cell_type":"code","execution_count":null,"metadata":{"id":"yVjnTvQsegc-"},"outputs":[],"source":["# Put your `generate_graph` function here\n","def generate_graph(pages):\n","  edges = pages.flatMapValues(lambda x: x).map(lambda x: (x[0], x[1][0])).distinct()\n","  vertices = edges.flatMap(lambda x: x).distinct().map(lambda x: (x,))\n","  return edges, vertices"],"id":"yVjnTvQsegc-"},{"cell_type":"code","execution_count":null,"metadata":{"id":"db005700","nbgrader":{"grade":false,"grade_id":"cell-PageRank","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["t_start = time()\n","\n","pages_links = spark.read.parquet(\"gs://wikidata_preprocessed/*\").select(\"id\", \"anchor_text\").rdd\n","\n","# construct the graph \n","edges, vertices = generate_graph(pages_links)\n","\n","# compute PageRank\n","edgesDF = edges.toDF(['src', 'dst']).repartition(124, 'src')\n","verticesDF = vertices.toDF(['id']).repartition(124, 'id')\n","\n","g = GraphFrame(verticesDF, edgesDF)\n","pr_results = g.pageRank(resetProbability=0.15, maxIter=6)\n","pr = pr_results.vertices.select(\"id\", \"pagerank\")\n","pr = pr.sort(col('pagerank').desc())\n","pr.repartition(1).write.csv(f'gs://{bucket_name}/pagerank', compression=\"gzip\")\n","pr.show()\n","\n","pr_time = time() - t_start"],"id":"db005700"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2cc36ca9","nbgrader":{"grade":true,"grade_id":"cell-PageRank_time","locked":true,"points":10,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["# test that PageRank computaion took less than 1 hour\n","pr_time"],"id":"2cc36ca9"},{"cell_type":"markdown","metadata":{"id":"7f39m5R5TzZ2"},"source":["# Reporting"],"id":"7f39m5R5TzZ2"},{"cell_type":"markdown","metadata":{"id":"HDMJxXTFT4YU"},"source":["**YOUR TASK (5 points):** execute and complete the following lines to complete \n","the reporting requirements for assignment #3. "],"id":"HDMJxXTFT4YU"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0ec9661","nbgrader":{"grade":false,"grade_id":"cell-size_ofi_input_data","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"54595c29-4ae3-4b78-86d0-d8457ae9c150"},"outputs":[{"name":"stdout","output_type":"stream","text":["14.28 GiB    gs://wikidata_preprocessed\r\n"]}],"source":["# size of input data\n","!gsutil du -sh \"gs://wikidata_preprocessed/\""],"id":"a0ec9661"},{"cell_type":"code","execution_count":null,"metadata":{"id":"264e0792","nbgrader":{"grade":false,"grade_id":"cell-size_of_index_data","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"44d9721a-1cd7-4e59-9f78-5439864cfdad"},"outputs":[{"name":"stdout","output_type":"stream","text":["5.93 GiB     gs://sise_ir_assignment3/postings_gcp\r\n"]}],"source":["# size of index data\n","index_dst = f'gs://{bucket_name}/body_index/'\n","!gsutil du -sh \"$index_dst\""],"id":"264e0792"}],"metadata":{"celltoolbar":"Create Assignment","colab":{"collapsed_sections":[],"name":"inverted_index_body_gcp.ipynb","provenance":[{"file_id":"1KEW1IZ6BlWN9esQv8IbD0JLFX3hMp_k_","timestamp":1641674109643}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":5}